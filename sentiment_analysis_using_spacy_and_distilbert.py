# -*- coding: utf-8 -*-
"""Sentiment_analysis_using_spaCy_and_DistilBERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QCbBitx3XMyJAeyLCQ-_8-KYtJG-d1D6
"""

# Commented out IPython magic to ensure Python compatibility.
#import libraries
import pandas as pd
import spacy
import csv
import seaborn as sns
import matplotlib.pyplot as plt

#install spaCy
!pip install spacy

#download the english language model for spaCy
!python -m spacy download en_core_web_sm

#load the english model
nlp = spacy.load("en_core_web_sm")


#load the file for analysis
file_path = '/content/sentiment_analysis_examples.txt'
with open(file_path, 'r', encoding='utf-8') as file:
    sentiment_texts = file.readlines()

token_lists = []  #list to store tokens for each sentiment example

#process each sentiment example using spaCy and store the results
for sentiment_text in sentiment_texts:
    doc = nlp(sentiment_text.strip())  #strip any leading/trailing whitespace

    tokens = [token.text for token in doc]  #extract tokens from the processed text
    token_lists.append(tokens)  #append tokens list to token_lists

#create a DataFrame to organize the results for sentiment examples
results_df = pd.DataFrame({
    'Sentiment Example': sentiment_texts,
    'Tokens': token_lists})

#display the DataFrame
print("Sentiment Example Tokens:")
print(results_df)

#import libraries
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
!pip install wordcloud matplotlib
# %matplotlib inline

#load CSV file into a DataFrame without header
df = pd.read_csv("/content/sentiment_analysis_examples.csv", header=None)
df.head()
df.info()

#import the DistilBertModel from transformers library
from transformers import pipeline, DistilBertModel, DistilBertTokenizer

#load pre-trained DistilBERT model and tokenizer
model = DistilBertModel.from_pretrained('distilbert-base-uncased')
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')

#this method assigned a STAR rating automatically to an unstructured text.
#so, we take unlabeled data, perform sentiment analysis using DistilBERT and it gives a score!""

#load DistilBERT sentiment analysis pipeline
sentiment_analysis_bert = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")


#iterate over the rows and perform sentiment analysis with DistilBERT
sentiment_results_bert = []
for index, row in df.iterrows():
    text = row[0]
    bert_result = sentiment_analysis_bert(text)[0]
    sentiment_label_bert = bert_result['label']
    sentiment_score_bert = bert_result['score']
    sentiment_results_bert.append({"Text": text, "Sentiment Score": sentiment_score_bert, "Sentiment Label": sentiment_label_bert})


#iterate over the sentiment results and print each entry
for result in sentiment_results_bert:
    print(f"Text: {result['Text']}")
    print(f"Sentiment Score: {result['Sentiment Score']}")
    print(f"Sentiment Label: {result['Sentiment Label']}")
    print()

#convert DistilBERT sentiment results to DataFrame
sentiment_df_bert = pd.DataFrame(sentiment_results_bert)

#save DistilBERT sentiment results to a new CSV file
sentiment_df_bert.to_csv("sentiment_results_bert.csv", index=False)

sentiment_df_bert.head()

#count the occurrences of each sentiment label
sentiment_label_counts = sentiment_df_bert['Sentiment Label'].value_counts()

#plotting pie chart for sentiment labels
plt.figure(figsize=(8, 6))
plt.pie(sentiment_label_counts, labels=sentiment_label_counts.index, autopct='%1.1f%%', startangle=140)
plt.title('Distribution of Sentiment Labels')
plt.show()

#count the occurrences of each sentiment label for visualization
sentiment_label_counts = sentiment_df_bert['Sentiment Label'].value_counts()

#plotting stacked bar chart for sentiment labels
plt.figure(figsize=(10, 6))
sentiment_label_counts.plot(kind='bar', stacked=True)
plt.title('Bar Chart of Sentiment Labels')
plt.xlabel('Sentiment Label')
plt.ylabel('Frequency Count')
plt.show()